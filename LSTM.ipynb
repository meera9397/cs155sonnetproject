{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89841\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Lambda, Dropout, Flatten\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load in text \n",
    "raw_text = open(os.path.join(os.getcwd(), 'data_shakespeare/shakespeare.txt')).read()\n",
    "lines = [line.split() for line in raw_text.split('\\n\\n') if line.split()]\n",
    "\n",
    "# remove all unnecessary characters from the text\n",
    "raw_text2 = ''\n",
    "for line in lines:\n",
    "    obs_elem = []\n",
    "    for word in line:\n",
    "        word = re.sub(\"\\d+\", \"\", word)\n",
    "        if (word == \"\"):\n",
    "            continue\n",
    "        word = re.sub(r'[^-\\w\\']', '', word).lower()\n",
    "        raw_text2 += word + ' '\n",
    "            \n",
    "# create same-length strings \n",
    "length = 40\n",
    "# get list of all characters used in text\n",
    "chars = sorted(list(set(raw_text2)))\n",
    "# map characters to their numerical value\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))\n",
    "vocab_size = len(mapping)\n",
    "print(len(raw_text2))\n",
    "# tokenize a 40 length sequence and the character\n",
    "# coming after it (the 40 length sequence will be \n",
    "# x and the 41st character will be y)\n",
    "X = []\n",
    "y = []\n",
    "# using semi-redundant sequences to speed up training\n",
    "for i in range(length, 500):\n",
    "    # select sequence of tokens\n",
    "    seq = raw_text2[i-length:i+1]\n",
    "    # store\n",
    "    encoded_seq = [mapping[c] for c in list(seq)]\n",
    "    X.append(np.array(encoded_seq))\n",
    "    output = raw_text2[i + 1]\n",
    "    encoded_seq2 = mapping[output]\n",
    "    y.append(encoded_seq2)\n",
    "    \n",
    "# separate into input and output\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "beforepX = X\n",
    "# converts x and y to binary class matrices (depending on \n",
    "# if the character is present in that sequence)\n",
    "newsequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = np.array(newsequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "               \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 41, 29) (460, 29)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate poem from Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(model, chars):\n",
    "    ''' passing in a trained model and all the characters\n",
    "    that the model was trained on, generates a poem based\n",
    "    on model predictions '''\n",
    "    # get random initial line\n",
    "    start = np.random.randint(0, len(beforepX)-1)\n",
    "    # dictionary converting integers to characters\n",
    "    # (since we will generate predictions that are int sequences,\n",
    "    # we convert them to characters)\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    # get a random seed from the input data\n",
    "    pattern = list(beforepX[start])\n",
    "    # generate characters\n",
    "    # based on the input data, generate predictions \n",
    "    poem = ''\n",
    "    for k in range(700):\n",
    "        # get a prediction based on the pattern for what \n",
    "        # the next character will be \n",
    "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = to_categorical(x, num_classes=vocab_size)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        \n",
    "        # get prediction with highest probability \n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_char[index]\n",
    "        seq_in = [int_to_char[value] for value in pattern]\n",
    "        poem = poem + result\n",
    "        \n",
    "        # append that predicted pattern, remove first character \n",
    "        # from predicted pattern\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    # randomly add punctuation to poem, print poem out\n",
    "    punctuation_list = [',', '.', ':', '?']\n",
    "    punctuation_probs = [0.6, 0.1, 0.2, 0.1]\n",
    "    poem_format = poem.split()\n",
    "    for p in range(1, len(poem_format)):\n",
    "        if ((p - 1) % 10 == 0):\n",
    "            print(poem_format[p].capitalize() + ' ', end = '')\n",
    "        else:\n",
    "            if (poem_format[p] == 'i'):\n",
    "                print(poem_format[p].capitalize() + ' ', end = '')\n",
    "            else:\n",
    "                print(poem_format[p], end = '')\n",
    "            if (p % 10 == 0 and p < len(poem_format) - 1):\n",
    "                print(np.random.choice(punctuation_list, p = punctuation_probs) + ' ', end = '')\n",
    "                print()\n",
    "            elif(p == len(poem_format) - 1):\n",
    "                print('.', end = '')\n",
    "            else:\n",
    "                print(' ', end = '')\n",
    "        \n",
    "            \n",
    "def summers_day_poem(model, chars):\n",
    "    ''' passing in a trained model and all the characters\n",
    "    that the model was trained on, generates a poem based\n",
    "    on model predictions -- the input is set to be shall\n",
    "    i compare thee to a summers day'''\n",
    "        \n",
    "    test = \"shall i compare thee to a summers day tho\"\n",
    "    test = re.sub(\"\\d+\", \" \", test)\n",
    "    test = re.sub(r'[^-\\w\\']', ' ', test).lower()\n",
    "    pattern = [mapping[c] for c in list(test)]\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    # generate characters\n",
    "    poem = ''\n",
    "    for k in range(700):\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = to_categorical(x, num_classes=vocab_size)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_char[index]\n",
    "        seq_in = [int_to_char[value] for value in pattern]\n",
    "        poem = poem + result\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    punctuation_list = [',', '.', ':', '?']\n",
    "    punctuation_probs = [0.6, 0.1, 0.2, 0.1]\n",
    "    poem_format = poem.split()\n",
    "    for p in range(1, len(poem_format)):\n",
    "        if ((p - 1) % 10 == 0):\n",
    "            print(poem_format[p].capitalize() + ' ', end = '')\n",
    "        else:\n",
    "            if (poem_format[p] == 'i'):\n",
    "                print(poem_format[p].capitalize() + ' ', end = '')\n",
    "            else:\n",
    "                print(poem_format[p], end = '')\n",
    "            if (p % 10 == 0 and p < len(poem_format) - 1):\n",
    "                print(np.random.choice(punctuation_list, p = punctuation_probs) + ' ', end = '')\n",
    "                print()\n",
    "            elif(p == len(poem_format) - 1):\n",
    "                print('.', end = '')\n",
    "            else:\n",
    "                print(' ', end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer flatten_1: expected min_ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-593b56f56bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    473\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer flatten_1: expected min_ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "# adding temperature\n",
    "temp = 1.5\n",
    "model1.add(Lambda(lambda x : x /temp))\n",
    "model1.add(Dense(vocab_size, activation='softmax'))\n",
    "model1.add(Flatten())\n",
    "\n",
    "print(model1.summary())\n",
    "# compile model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "\n",
    "model1.fit(X, y, epochs=2, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(model1, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summers_day_poem(model1, chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "# adding temperature\n",
    "temp = 0.75\n",
    "model2.add(Lambda(lambda x : x /temp))\n",
    "model2.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "print(model2.summary())\n",
    "# compile model\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "\n",
    "model2.fit(X, y, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(model2, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summers_day_poem(model2, chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model3.add(Dropout(0.3))\n",
    "\n",
    "# adding temperature\n",
    "temp = 0.25\n",
    "model3.add(Lambda(lambda x : x /temp))\n",
    "model3.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "print(model3.summary())\n",
    "# compile model\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "\n",
    "model3.fit(X, y, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(model3, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summers_day_poem(model3, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
