{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91006\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Lambda, Dropout\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load in text \n",
    "raw_text = open(os.path.join(os.getcwd(), 'data_shakespeare/shakespeare.txt')).read()\n",
    "lines = [line.split() for line in raw_text.split('\\n\\n') if line.split()]\n",
    "\n",
    "# remove all unnecessary characters from the text\n",
    "raw_text2 = ''\n",
    "for line in lines:\n",
    "    obs_elem = []\n",
    "    for word in line:\n",
    "        word = re.sub(\"\\d+\", \"\", word)\n",
    "        if (word == \"\"):\n",
    "            continue\n",
    "        word = re.sub(r'[^-\\w\\']', '', word).lower()\n",
    "        raw_text2 += word + ' '\n",
    "            \n",
    "# create same-length strings \n",
    "length = 40\n",
    "# get list of all characters used in text\n",
    "chars = sorted(list(set(raw_text2)))\n",
    "# map characters to their numerical value\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))\n",
    "vocab_size = len(mapping)\n",
    "print(len(raw_text2))\n",
    "# tokenize a 40 length sequence and the character\n",
    "# coming after it (the 40 length sequence will be \n",
    "# x and the 41st character will be y)\n",
    "X = []\n",
    "y = []\n",
    "# using semi-redundant sequences to speed up training\n",
    "for i in range(length, len(raw_text2) - 1):\n",
    "    # select sequence of tokens\n",
    "    seq = raw_text2[i-length:i+1]\n",
    "    # store\n",
    "    encoded_seq = [mapping[c] for c in list(seq)]\n",
    "    X.append(np.array(encoded_seq))\n",
    "    output = raw_text2[i + 1]\n",
    "    encoded_seq2 = mapping[output]\n",
    "    y.append(encoded_seq2)\n",
    "    \n",
    "# separate into input and output\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "beforepX = X\n",
    "# converts x and y to binary class matrices (depending on \n",
    "# if the character is present in that sequence)\n",
    "newsequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = np.array(newsequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate poem from Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(model, chars):\n",
    "    ''' passing in a trained model and all the characters\n",
    "    that the model was trained on, generates a poem based\n",
    "    on model predictions '''\n",
    "    # get random initial line\n",
    "    start = np.random.randint(0, len(beforepX)-1)\n",
    "    # dictionary converting integers to characters\n",
    "    # (since we will generate predictions that are int sequences,\n",
    "    # we convert them to characters)\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    # get a random seed from the input data\n",
    "    pattern = list(beforepX[start])\n",
    "    # generate characters\n",
    "    # based on the input data, generate predictions \n",
    "    poem = ''\n",
    "    for k in range(700):\n",
    "        # get a prediction based on the pattern for what \n",
    "        # the next character will be \n",
    "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = to_categorical(x, num_classes=vocab_size)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        \n",
    "        # get prediction with highest probability \n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_char[index]\n",
    "        seq_in = [int_to_char[value] for value in pattern]\n",
    "        poem = poem + result\n",
    "        \n",
    "        # append that predicted pattern, remove first character \n",
    "        # from predicted pattern\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    # randomly add punctuation to poem, print poem out\n",
    "    punctuation_list = [',', '.', ':', '?']\n",
    "    punctuation_probs = [0.6, 0.1, 0.2, 0.1]\n",
    "    poem_format = poem.split()\n",
    "    for p in range(1, len(poem_format)):\n",
    "        if ((p - 1) % 10 == 0):\n",
    "            print(poem_format[p].capitalize() + ' ', end = '')\n",
    "        else:\n",
    "            if (poem_format[p] == 'i'):\n",
    "                print(poem_format[p].capitalize() + ' ', end = '')\n",
    "            else:\n",
    "                print(poem_format[p], end = '')\n",
    "            if (p % 10 == 0 and p < len(poem_format) - 1):\n",
    "                print(np.random.choice(punctuation_list, p = punctuation_probs) + ' ', end = '')\n",
    "                print()\n",
    "            elif(p == len(poem_format) - 1):\n",
    "                print('.', end = '')\n",
    "            else:\n",
    "                print(' ', end = '')\n",
    "        \n",
    "            \n",
    "def summers_day_poem(model, chars):\n",
    "    ''' passing in a trained model and all the characters\n",
    "    that the model was trained on, generates a poem based\n",
    "    on model predictions -- the input is set to be shall\n",
    "    i compare thee to a summers day'''\n",
    "        \n",
    "    test = \"shall i compare thee to a summers day tho\"\n",
    "    test = re.sub(\"\\d+\", \" \", test)\n",
    "    test = re.sub(r'[^-\\w\\']', ' ', test).lower()\n",
    "    pattern = [mapping[c] for c in list(test)]\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    # generate characters\n",
    "    poem = ''\n",
    "    for k in range(700):\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = to_categorical(x, num_classes=vocab_size)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_char[index]\n",
    "        seq_in = [int_to_char[value] for value in pattern]\n",
    "        poem = poem + result\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    punctuation_list = [',', '.', ':', '?']\n",
    "    punctuation_probs = [0.6, 0.1, 0.2, 0.1]\n",
    "    poem_format = poem.split()\n",
    "    for p in range(1, len(poem_format)):\n",
    "        if ((p - 1) % 10 == 0):\n",
    "            print(poem_format[p].capitalize() + ' ', end = '')\n",
    "        else:\n",
    "            if (poem_format[p] == 'i'):\n",
    "                print(poem_format[p].capitalize() + ' ', end = '')\n",
    "            else:\n",
    "                print(poem_format[p], end = '')\n",
    "            if (p % 10 == 0 and p < len(poem_format) - 1):\n",
    "                print(np.random.choice(punctuation_list, p = punctuation_probs) + ' ', end = '')\n",
    "                print()\n",
    "            elif(p == len(poem_format) - 1):\n",
    "                print('.', end = '')\n",
    "            else:\n",
    "                print(' ', end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 200)               184000    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 29)                5829      \n",
      "=================================================================\n",
      "Total params: 189,829\n",
      "Trainable params: 189,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/90\n",
      " - 138s - loss: 2.4598 - acc: 0.2945\n",
      "Epoch 2/90\n",
      " - 114s - loss: 2.0767 - acc: 0.3870\n",
      "Epoch 3/90\n",
      " - 114s - loss: 1.9420 - acc: 0.4179\n",
      "Epoch 4/90\n",
      " - 118s - loss: 1.8574 - acc: 0.4417\n",
      "Epoch 5/90\n",
      " - 132s - loss: 1.7921 - acc: 0.4586\n",
      "Epoch 6/90\n",
      " - 131s - loss: 1.7339 - acc: 0.4708\n",
      "Epoch 7/90\n",
      " - 133s - loss: 1.6874 - acc: 0.4829\n",
      "Epoch 8/90\n",
      " - 134s - loss: 1.6434 - acc: 0.4930\n",
      "Epoch 9/90\n",
      " - 124s - loss: 1.6088 - acc: 0.5015\n",
      "Epoch 10/90\n",
      " - 131s - loss: 1.5647 - acc: 0.5140\n",
      "Epoch 11/90\n",
      " - 128s - loss: 1.5261 - acc: 0.5250\n",
      "Epoch 12/90\n",
      " - 128s - loss: 1.4844 - acc: 0.5365\n",
      "Epoch 13/90\n",
      " - 130s - loss: 1.4460 - acc: 0.5455\n",
      "Epoch 14/90\n",
      " - 128s - loss: 1.4075 - acc: 0.5578\n",
      "Epoch 15/90\n",
      " - 121s - loss: 1.3677 - acc: 0.5709\n",
      "Epoch 16/90\n",
      " - 108s - loss: 1.3295 - acc: 0.5797\n",
      "Epoch 17/90\n",
      " - 108s - loss: 1.2944 - acc: 0.5904\n",
      "Epoch 18/90\n",
      " - 4000s - loss: 1.2605 - acc: 0.5996\n",
      "Epoch 19/90\n",
      " - 110s - loss: 1.2291 - acc: 0.6101\n",
      "Epoch 20/90\n",
      " - 110s - loss: 1.2002 - acc: 0.6196\n",
      "Epoch 21/90\n",
      " - 108s - loss: 1.1677 - acc: 0.6285\n",
      "Epoch 22/90\n",
      " - 110s - loss: 1.1441 - acc: 0.6330\n",
      "Epoch 23/90\n",
      " - 108s - loss: 1.1218 - acc: 0.6407\n",
      "Epoch 24/90\n",
      " - 108s - loss: 1.0984 - acc: 0.6484\n",
      "Epoch 25/90\n",
      " - 7305s - loss: 1.0824 - acc: 0.6539\n",
      "Epoch 26/90\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "# adding temperature\n",
    "temp = 1.5\n",
    "model1.add(Lambda(lambda x : x /temp))\n",
    "model1.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "print(model1.summary())\n",
    "# compile model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "\n",
    "model1.fit(X, y, epochs=90, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(model1, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summers_day_poem(model1, chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "# adding temperature\n",
    "temp = 0.75\n",
    "model2.add(Lambda(lambda x : x /temp))\n",
    "model2.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "print(model2.summary())\n",
    "# compile model\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "\n",
    "model2.fit(X, y, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(model2, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summers_day_poem(model2, chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model3.add(Dropout(0.3))\n",
    "\n",
    "# adding temperature\n",
    "temp = 0.25\n",
    "model3.add(Lambda(lambda x : x /temp))\n",
    "model3.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "print(model3.summary())\n",
    "# compile model\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "\n",
    "model3.fit(X, y, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(model3, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summers_day_poem(model3, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
